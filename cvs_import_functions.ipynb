{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43895ef9",
   "metadata": {},
   "source": [
    "## Import a CVS file into a database using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab04076",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89c25f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy\n",
    "import pandas as pd\n",
    "import psycopg2 as pg2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf784ff",
   "metadata": {},
   "source": [
    "### Find CVS files in working directory and move them in a separate file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4bb4b48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Isolate CVS files\n",
    "#Make new directory\n",
    "#Move the files in the directory\n",
    "def csv_files():\n",
    "    #get names of only csv files\n",
    "    csv_files = []\n",
    "    for file in os.listdir(os.getcwd()):\n",
    "        if file.endswith(\".csv\"):\n",
    "            csv_files.append(file)\n",
    "\n",
    "    return csv_files\n",
    "\n",
    "#Create new directory by using bash command\n",
    "def configure_dataset_directory(csv_files, dataset_dir):\n",
    "  \n",
    "    #make dataset folder to process csv files\n",
    "    #Error handling in case file already exists\n",
    "    try: \n",
    "      mkdir = 'mkdir {0}'.format(dataset_dir)\n",
    "      os.system(mkdir)\n",
    "    except:\n",
    "      pass\n",
    "\n",
    "    #move csv files to dataset folder\n",
    "    for csv in csv_files:\n",
    "      mv_file = \"mv '{0}' {1}\".format(csv, dataset_dir)\n",
    "      os.system(mv_file)\n",
    "\n",
    "    return\n",
    "\n",
    "#Create new directory\n",
    "def create_df(dataset_dir, csv_files):\n",
    "  \n",
    "    data_path = os.getcwd()+'/'+dataset_dir+'/'\n",
    "\n",
    "    #loop through the files and create the dataframe\n",
    "    df = {}\n",
    "    for file in csv_files:\n",
    "        try:\n",
    "            df[file] = pd.read_csv(data_path+file)\n",
    "        except UnicodeDecodeError:\n",
    "            df[file] = pd.read_csv(data_path+file, encoding=\"ISO-8859-1\") #if utf-8 encoding error\n",
    "        print(file)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430171d3",
   "metadata": {},
   "source": [
    "### Import cvs files into a panda dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d502058a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(dataset_dir, csv_files):\n",
    "  \n",
    "    data_path = os.getcwd()+'/'+dataset_dir+'/'\n",
    "\n",
    "    #loop through the files and create the dataframe\n",
    "    df = {}\n",
    "    for file in csv_files:\n",
    "        try:\n",
    "            df[file] = pd.read_csv(data_path+file)\n",
    "        except UnicodeDecodeError:\n",
    "            df[file] = pd.read_csv(data_path+file, encoding=\"ISO-8859-1\") #if utf-8 encoding error\n",
    "        print(file)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc44c5e",
   "metadata": {},
   "source": [
    "### Clean and format table names\n",
    "The rules are:\n",
    "- lower case letters\n",
    "- remove all white spaces and S\n",
    "- replace -,/, \\\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca2823c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tbl_name(filename):\n",
    "  \n",
    "    #rename csv, force lower case, no spaces, no dashes\n",
    "    clean_tbl_name = filename.lower().replace(\" \", \"\").replace(\"-\",\"_\").replace(r\"/\",\"_\").replace(\"\\\\\",\"_\").replace(\"$\",\"\").replace(\"%\",\"\")\n",
    "    \n",
    "    tbl_name = '{0}'.format(clean_tbl_name.split('.')[0])\n",
    "\n",
    "    return tbl_name\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79182fc",
   "metadata": {},
   "source": [
    "### Format header and replace data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a42bcbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_colname(dataframe):\n",
    "  \n",
    "    #force column names to be lower case, no spaces, no dashes\n",
    "    dataframe.columns = [x.lower().replace(\" \", \"_\").replace(\"-\",\"_\").replace(r\"/\",\"_\").replace(\"\\\\\",\"_\").replace(\".\",\"_\").replace(\"$\",\"\").replace(\"%\",\"\") for x in dataframe.columns]\n",
    "    \n",
    "    #processing data\n",
    "    replacements = {\n",
    "        'timedelta64[ns]': 'varchar',\n",
    "        'object': 'varchar',\n",
    "        'float64': 'float',\n",
    "        'int64': 'int',\n",
    "        'datetime64': 'timestamp'\n",
    "    }\n",
    "\n",
    "    col_str = \", \".join(\"{} {}\".format(n, d) for (n, d) in zip(dataframe.columns, dataframe.dtypes.replace(replacements)))\n",
    "    \n",
    "    return col_str, dataframe.columns\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d08a64",
   "metadata": {},
   "source": [
    "### Write the create table SQL statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336fdff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upload_to_db(dbname, user, password, tbl_name, col_str, file, dataframe, dataframe_columns):\n",
    "\n",
    "    conn_string = \"dbname=%s user=%s password=%s\" % (dbname, user, password)\n",
    "    conn = psycopg2.connect(conn_string)\n",
    "    cursor = conn.cursor()\n",
    "    print('opened database successfully')\n",
    "    \n",
    "    #drop table with same name\n",
    "    cursor.execute(\"drop table if exists %s;\" % (tbl_name))\n",
    "\n",
    "    #create table\n",
    "    cursor.execute(\"create table %s (%s);\" % (tbl_name, col_str))\n",
    "    print('{0} was created successfully'.format(tbl_name)) \n",
    "    \n",
    "    #insert values to table\n",
    "\n",
    "    #save df to csv\n",
    "    dataframe.to_csv(file, header=dataframe_columns, index=False, encoding='utf-8')\n",
    "\n",
    "    #open the csv file, save it as an object\n",
    "    my_file = open(file)\n",
    "    print('file opened in memory')\n",
    "    \n",
    "    #upload to db\n",
    "    SQL_STATEMENT = \"\"\"\n",
    "    COPY %s FROM STDIN WITH\n",
    "        CSV\n",
    "        HEADER\n",
    "        DELIMITER AS ','\n",
    "    \"\"\"\n",
    "\n",
    "    cursor.copy_expert(sql=SQL_STATEMENT % tbl_name, file=my_file)\n",
    "    print('file copied to db')\n",
    "    \n",
    "    cursor.execute(\"grant select on table %s to public\" % tbl_name)\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    print('table {0} imported to db completed'.format(tbl_name))\n",
    "\n",
    "    return"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
